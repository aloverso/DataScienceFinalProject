{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "This notebook served as our exploration for the sessions of Congress where we had bill data and were able to extract what subjects Congress was voting on during that session from our data scraping and cleaning phase of the project.\n",
    "\n",
    "This notebook accomplishes two important things. The first is determing what subjects are most important to each session of Congress. We initially tried attempts like counting the subjects that appeared the most often per session or looking at the intersection of the sets of subjects for all sessions of Congress or even grouping similar sessions together. What we found, ultimately, is that Congress self-references both itself and the federal government as a whole, with the most common subject amongst most sessions being 'Government operations and politics', which isn't particularly insightful.\n",
    "\n",
    "As a result, we used tfidf to find the most relevant subjects to each session of Congress. We treat each session as essentially a document where a record of a vote on a subject means that subject appears in the document once and 20 votes on a subject means that subject appears 20 times in that document, the corpus being all of our sessions of Congress. Using tfidf, we found subjects relevant to each session of Congress but we were still finding some self-referential subjects, like 'Bill consideration (Rule)' which appeared only in the first few sessions we had this bill data for and thus did not have a significant idf component to outweigh it's high tf score. Our only path was raw filtering of the subjects, filtering out all subjects that contain 'Congress', 'Government', 'Bill', 'Advisory', 'Executive', 'Public', and 'Federal' keywords.\n",
    "\n",
    "After running tfidf, we knew what subjects were most important to each individual session but we wanted to have more granularity. What we did next was go through all the subjects and record every date where at least one bill concerning one of these most relevant subjects was voted on in Congress. This let us create a very fine resolution graph of the day-to-day of Congress and is contained in our website [here](http://zoherghadyali.me/DataScienceFinalProject/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports the packages we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We go through and we look for all sessions of Congress that we know we have subject data for from our previous data scraping and cleaning phase. If any of the .csv files have any sponsors, then that means we have bill data which means we have subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['93house', '93senate', '94house', '94senate', '95house', '95senate', '96house', '97house', '98house', '101house', '101senate', '102house', '102senate', '103house', '103senate', '104house', '104senate', '105house', '105senate', '106house', '106senate', '107house', '107senate', '108house', '108senate', '109house', '109senate', '110house', '110senate', '111house', '111senate', '112house', '112senate', '113house', '113senate']\n"
     ]
    }
   ],
   "source": [
    "with_subjects = []\n",
    "\n",
    "for congress_no in range(1, 114):\n",
    "    for body in ['house', 'senate']:\n",
    "        df = pd.read_csv('data/congress_sessions_legislation/' + str(congress_no) + body + '.csv', low_memory=False)\n",
    "        if not df.sponsor[df.sponsor != 'unknown'].empty: #df.sponsor is unknown when we have no bill data, any non \"unknown\"s means we have bill data\n",
    "            with_subjects.append(str(congress_no) + body)\n",
    "\n",
    "print with_subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know which sessions have subject data, we go through all of them and grab all of the subjects and store each session's subjects as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subjects = []\n",
    "for session in with_subjects:\n",
    "    df = pd.read_csv('data/congress_sessions_legislation/' + session + '.csv', low_memory=False)\n",
    "    columns = list(df.columns.values) #grabs all of the fields in the .csv files, between title and billTitle are all of our subjects\n",
    "    subjects.append(columns[columns.index('title')+1:columns.index('billTitle')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply the filtering on the subjects discussed in the summary at the top of this notebook, filtering out all subjects that refer to 'Congress', 'Government', 'Bill', 'Advisory', 'Executive', 'Federal', and 'Public'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filteredSubjects = []\n",
    "for subjectlist in subjects:\n",
    "    res = []\n",
    "    for subject in subjectlist:\n",
    "        if 'Congress' not in subject and 'Government' not in subject and 'Bill' not in subject and 'Advisory' not in subject and 'Executive' not in subject and 'Public' not in subject and 'Federal' not in subject:\n",
    "            res.append(subject)\n",
    "    filteredSubjects.append(res)\n",
    "\n",
    "subjects = filteredSubjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the tf part of tfidf where we count, within each document, the subjects that appear the most often. Before filtering, this subject would have been 'Government operations and politics' for most of the sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subjects_count = []\n",
    "for i in range(0, len(with_subjects)):\n",
    "    df = pd.read_csv('data/congress_sessions_legislation/' + with_subjects[i] + '.csv', low_memory=False)\n",
    "    res = []\n",
    "    for subject in subjects[i]:\n",
    "        res.append(len(df[subject][df[subject] == 1])) #counts the number of votes that related to this subject (thus the number of times this subject will appear in the document)\n",
    "    subjects_count.append(res)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a sanity check to make sure that for every subject we have recorded, we also have a count of how many times bills related to that subject were voted on and to ensure that for each subject, an accurate count was obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465\n",
      "465\n",
      "Aerial bombing\n",
      "6\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print len(subjects[0])\n",
    "print len(subjects_count[0])  \n",
    "\n",
    "index = 2\n",
    "print subjects[0][index]\n",
    "print subjects_count[0][index]\n",
    "\n",
    "df = pd.read_csv('data/congress_sessions_legislation/93house.csv', low_memory=False)\n",
    "print len(df[subjects[0][index]][df[subjects[0][index]] ==1 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the subjects_tot_count dictionary is to create a master list of all the subjects in all sessions of Congress which we need for the idf part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subjects_tot_count = {}\n",
    "for i in range(0, len(subjects)):\n",
    "    for j in range(0, len(subjects[i])):\n",
    "        if subjects[i][j] in subjects_tot_count:\n",
    "            subjects_tot_count[subjects[i][j]] += subjects_count[i][j]\n",
    "        else:\n",
    "            subjects_tot_count[subjects[i][j]] = subjects_count[i][j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we go through all the subjects and count how many sessions, of the 35 we have this bill data for, a given subject appears. We then take the log of the total number of sessions divided by the count to get our idf score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subjects_idf = {}\n",
    "for key in subjects_tot_count:\n",
    "    count = 0\n",
    "    for subjectlist in subjects:\n",
    "        if key in subjectlist:\n",
    "            count += 1\n",
    "    subjects_idf[key] = np.log(float(len(with_subjects))/count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the tfidf score, found by taking the product of the total number of times a subject appears within a given session and the idf score for the given subject, for each subject in each session of Congress. We loop through all of the subjects and find the highest tfidf scorer and thus the most relevant subject to that session (the one that was voted on the most times but is not common to the other sessions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "93house\n",
      "Medical care, personnel, and facilities\n",
      "78.0859332133\n",
      "------------\n",
      "93senate\n",
      "Petroleum and petroleum products\n",
      "99.1430143432\n",
      "------------\n",
      "94house\n",
      "Petroleum and petroleum products\n",
      "148.035459773\n",
      "------------\n",
      "94senate\n",
      "Value-added tax\n",
      "223.975751217\n",
      "------------\n",
      "95house\n",
      "Agriculture and Rural Affairs\n",
      "270.481510719\n",
      "------------\n",
      "95senate\n",
      "Agriculture and Rural Affairs\n",
      "215.996026545\n",
      "------------\n",
      "96house\n",
      "Foreign Trade and Investments\n",
      "319.375650467\n",
      "------------\n",
      "97house\n",
      "Defense articles\n",
      "154.774353688\n",
      "------------\n",
      "98house\n",
      "Agriculture and Rural Affairs\n",
      "251.022409228\n",
      "------------\n",
      "101house\n",
      "Narcotic traffic\n",
      "109.934256147\n",
      "------------\n",
      "101senate\n",
      "Narcotic traffic\n",
      "149.550204308\n",
      "------------\n",
      "102house\n",
      "Narcotic traffic\n",
      "206.993329142\n",
      "------------\n",
      "102senate\n",
      "Narcotic traffic\n",
      "88.1454846585\n",
      "------------\n",
      "103house\n",
      "Narcotic traffic\n",
      "306.033199545\n",
      "------------\n",
      "103senate\n",
      "Narcotic traffic\n",
      "168.367779685\n",
      "------------\n",
      "104house\n",
      "Educational policy\n",
      "412.005860876\n",
      "------------\n",
      "104senate\n",
      "Welfare reform\n",
      "277.611142329\n",
      "------------\n",
      "105house\n",
      "Computers and government\n",
      "262.059149316\n",
      "------------\n",
      "105senate\n",
      "Hazardous waste site remediation\n",
      "147.590651981\n",
      "------------\n",
      "106house\n",
      "Hazardous waste site remediation\n",
      "312.8921822\n",
      "------------\n",
      "106senate\n",
      "Hazardous waste site remediation\n",
      "159.397904139\n",
      "------------\n",
      "107house\n",
      "EBB Terrorism\n",
      "281.976981048\n",
      "------------\n",
      "107senate\n",
      "Education of disabled students\n",
      "190.467567964\n",
      "------------\n",
      "108house\n",
      "Electronic government information\n",
      "293.705397442\n",
      "------------\n",
      "108senate\n",
      "EBB Terrorism\n",
      "262.455497745\n",
      "------------\n",
      "109house\n",
      "Hurricane aftermath legislation\n",
      "549.542569138\n",
      "------------\n",
      "109senate\n",
      "Hurricane aftermath legislation\n",
      "329.153101307\n",
      "------------\n",
      "110house\n",
      "Iraq compilation\n",
      "333.318243937\n",
      "------------\n",
      "110senate\n",
      "Iraq compilation\n",
      "333.318243937\n",
      "------------\n",
      "111house\n",
      "Research administration and funding\n",
      "479.696097095\n",
      "------------\n",
      "111senate\n",
      "Fraud offenses and financial crimes\n",
      "289.228529131\n",
      "------------\n",
      "112house\n",
      "Research administration and funding\n",
      "906.484536422\n",
      "------------\n",
      "112senate\n",
      "Rural conditions and development\n",
      "261.011111655\n",
      "------------\n",
      "113house\n",
      "Research administration and funding\n",
      "481.459685687\n",
      "------------\n",
      "113senate\n",
      "Education programs funding\n",
      "186.94039078\n"
     ]
    }
   ],
   "source": [
    "tfidf = []\n",
    "for i in range(0, len(subjects)):\n",
    "    res = []\n",
    "    for j in range(0, len(subjects[i])):\n",
    "        res.append(subjects_count[i][j] * subjects_idf[subjects[i][j]])\n",
    "    tfidf.append(res)\n",
    "\n",
    "tfidf_subjects = []\n",
    "for i in range(0, len(with_subjects)):\n",
    "    print '------------'\n",
    "    print with_subjects[i]\n",
    "    print subjects[i][tfidf[i].index(max(tfidf[i]))]\n",
    "    print max(tfidf[i])\n",
    "    tfidf_subjects.append(subjects[i][tfidf[i].index(max(tfidf[i]))])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to plot our raw findings, which would be the number of bills per year as we did [here](https://github.com/dinopants174/DataScienceFinalProject/blob/gh-pages/images/subject_filtering.png), we need to convert from individual sessions and houses to years. We did this by calculating the year based on the session number and creating a dictionary where the keys are years and the values are lists of the sessions, sometimes both House and Senate, and sometimes only one. We use this to make finding our .csv files and getting our data easier.\n",
    "\n",
    "We also see several repeats among our tfidf subjects, like 'Narcotic traffic' which has the highest tfidf score for 6 sessions straight so we eliminate the duplicates from our tfidf subject list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Electronic government information', 'Hurricane aftermath legislation', 'Education programs funding', 'Value-added tax', 'Agriculture and Rural Affairs', 'Hazardous waste site remediation', 'Education of disabled students', 'Defense articles', 'Foreign Trade and Investments', 'Research administration and funding', 'Fraud offenses and financial crimes', 'Narcotic traffic', 'Iraq compilation', 'EBB Terrorism', 'Medical care, personnel, and facilities', 'Rural conditions and development', 'Educational policy', 'Petroleum and petroleum products', 'Computers and government', 'Welfare reform']\n",
      "{2011: ['112house', '112senate'], 1989: ['101house', '101senate'], 1991: ['102house', '102senate'], 1993: ['103house', '103senate'], 2013: ['113house', '113senate'], 1995: ['104house', '104senate'], 1997: ['105house', '105senate'], 1999: ['106house', '106senate'], 2001: ['107house', '107senate'], 2009: ['111house', '111senate'], 2003: ['108house', '108senate'], 1973: ['93house', '93senate'], 2007: ['110house', '110senate'], 1975: ['94house', '94senate'], 1977: ['95house', '95senate'], 2005: ['109house', '109senate'], 1979: ['96house'], 1981: ['97house'], 1983: ['98house']}\n"
     ]
    }
   ],
   "source": [
    "years = [] #years will hold the calculate year for each session, the calculated year for 93house and 93senate will be the same (1973)\n",
    "           #so we can use that to when we create year_to_session\n",
    "\n",
    "for session in with_subjects:\n",
    "    tmp = ''\n",
    "    for char in session:\n",
    "        if char.isdigit():\n",
    "            tmp += char\n",
    "    if int(tmp) == 93:\n",
    "        years.append(int(tmp) + 1880) #corresponds to 1973, the first year we have subject data for\n",
    "    else:\n",
    "        years.append((int(tmp)-93)*2 + 1880 + 93) #since each session of Congress is 2 years, we have to increment the year by 2 for each session increment\n",
    "\n",
    "    \n",
    "year_to_session = {}\n",
    "for i in range(0, len(years)):\n",
    "    if years[i] in year_to_session:\n",
    "        year_to_session[years[i]].append(with_subjects[i])\n",
    "    else:\n",
    "        year_to_session[years[i]] = [with_subjects[i]]\n",
    "        \n",
    "filtered_tfidf_subjects = list(set(tfidf_subjects))\n",
    "\n",
    "print filtered_tfidf_subjects\n",
    "print year_to_session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the final iteration of the subjects visualization was done in d3.js, we write out the data we gather to an array in Javascript which we can then use to create our d3 visualization.\n",
    "\n",
    "We start by setting up our load_subjects.js file and then we loop through each of the years and each of the sessions. For each session, we loop through the tfidf subjects and find a dataframe that contains only votes on bills that addressed one of those subjects. We then assemble our JSON object using the data of that vote and the number of bills for each of the tfidf subjects.\n",
    "\n",
    "This method may produce repeated data, such as if a vote on a bill that concerned 'Electronic government information' also contained 'Educational policy', which means this is inefficient but overall should not affect our visualization other than data being replotted over itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "asc_years = sorted(year_to_session.keys()) #just means we go in order so our data array is reasonably sorted by year\n",
    "\n",
    "test = open('load_subjects.js', 'w')\n",
    "\n",
    "test.write('var data = ')\n",
    "\n",
    "lst = []\n",
    "\n",
    "for year in asc_years:\n",
    "    for session in year_to_session[year]:\n",
    "        df = pd.read_csv('data/congress_sessions_legislation/' + session + '.csv', low_memory=False)\n",
    "        for subject in filtered_tfidf_subjects:\n",
    "            if subject in list(df.columns.values):\n",
    "                tmp = df[df[subject]==1]\n",
    "                for date in list(set(tmp.date)):\n",
    "                    res = {}\n",
    "                    res['date'] = date\n",
    "                    for subject2 in filtered_tfidf_subjects:\n",
    "                        if subject2 in list(tmp.columns.values):\n",
    "                            res[subject2] = len(tmp[(tmp.date== date) & (tmp[subject2] == 1)])\n",
    "                        else:\n",
    "                            res[subject2] = 0\n",
    "                    lst.append(res)\n",
    "\n",
    "json.dump(lst, test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
