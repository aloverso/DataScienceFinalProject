{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "This notebook is basically an extension of [data_scraping_iter3.ipynb](https://github.com/dinopants174/DataScienceFinalProject/blob/gh-pages/data_scraping_iter3.ipynb) but requires the .csv files that were created from that notebook. In this notebook, we find all of the sessions where GovTrack has provided us with bill data so we know what specifically legislators from those sessions are voting on. We then add several fields to our .csv files using that bill data.\n",
    "\n",
    "Firstly, we create a matrix where the columns is a master list of all subjects addressed in that session and the rows for each column is a sequence of 1s and 0s, 1 if that bill relates to that subject and 0 if not. We get the main committee that that bill was in, the short title, the official title, and the name of the sponsor of the bill.\n",
    "\n",
    "Because we can only get the name of the sponsor, we will need a final additional step to replace the name with the actual accurate id for that legislator. That is contained in [reference_id.ipynb](https://github.com/dinopants174/DataScienceFinalProject/blob/gh-pages/reference_id.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports the packages we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finds all of the sessions of Congress where we have bill data to begin with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113]\n"
     ]
    }
   ],
   "source": [
    "contains_bills = []\n",
    "\n",
    "for i in range(1, 114):\n",
    "    path = '/media/anne/LACIE SHARE/DataScienceFinalProject/' + str(i) + '/bills'  #this path needs to be changed\n",
    "    if os.path.exists(path):\n",
    "        contains_bills.append(i)\n",
    "        \n",
    "print contains_bills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are our helper functions in adding the necessary fields outlined in the summary. find_subject_in_bills is used for finding a given subject in all of the bills and populating that bill's rows with 1s and 0s, appropriately. get_subjects gets all of the data we need for those fields using each bill's .json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_subject_in_bills(subject):\n",
    "    res = []\n",
    "    for i in range(0, len(tmp)): #tmp holds a list of objects for our bill data where each element corresponds to a vote\n",
    "        if type(tmp[i]) != dict: #that subject cannot be in that bill since we didn't get any bill data\n",
    "            res.append(0)\n",
    "        else:\n",
    "            if subject in tmp[i]['subjects']:  #if that bill relates to that subject, then so does that vote\n",
    "                res.append(1)\n",
    "            else:\n",
    "                res.append(0)\n",
    "    return res #each subject now has a list of 1s and 0s that show us the subjects each vote concerns\n",
    "\n",
    "def get_subjects(isAmendment, title):\n",
    "    if type(title) != str: #this means we weren't able to find the title so we won't be able to \n",
    "        tmp.append(np.nan)\n",
    "    else:\n",
    "        if isAmendment: #if we are dealing with an amendment, the first part is the amendment title, the second part is the bill title\n",
    "            if len(title.split()) > 1:\n",
    "                bill = title.split()[2]\n",
    "            else:\n",
    "                bill = title\n",
    "        else:\n",
    "            bill = title\n",
    "        #finds the path to the bill data\n",
    "        path = \"/media/anne/LACIE SHARE/DataScienceFinalProject/\" + str(congress_no) + \"/bills/\" + ''.join([i for i in bill if not i.isdigit()]) + \"/\" + bill + \"/data.json\"\n",
    "        if os.path.exists(path): #checks if bill .json exists\n",
    "            f = open(path, 'r')\n",
    "            vote = json.loads(f.read(), 'utf-8')\n",
    "            obj = {}\n",
    "            if 'subjects' in vote:  #gets all the subjects and stores them as a list\n",
    "                obj['subjects'] = vote['subjects']\n",
    "            else:\n",
    "                obj['subjects'] = np.nan\n",
    "            if len(vote['committees']): #the first committee should be the one the bill originated in\n",
    "                obj['committee'] = vote['committees'][0]['committee']\n",
    "            else:\n",
    "                obj['committee'] = np.nan\n",
    "            if 'short_title' in vote: #gets the short title\n",
    "                obj['billTitle'] = vote['short_title']\n",
    "            else:\n",
    "                obj['billTitle'] = np.nan\n",
    "            if 'official_title' in vote: #gets the official title\n",
    "                obj['officialTitle'] = vote['official_title']\n",
    "            else:\n",
    "                obj['officialTitle'] = np.nan\n",
    "            if 'sponsor' in vote and vote['sponsor']: #we get the sponsor name and format it to match our legislators data for reference_id.ipynb\n",
    "                name = vote['sponsor']['name'].split(', ')\n",
    "                filtered_name = name[1] + \"#\" + name[0] + \"#\" + vote['sponsor']['state']\n",
    "                obj['sponsor'] = filtered_name\n",
    "            else:\n",
    "                obj['sponsor'] = np.nan\n",
    "            tmp.append(obj) #tmp holds a list of objects for our bill dataa and each element corresponds to a vote\n",
    "        else:\n",
    "            tmp.append(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the helper functions above, we loop through all the sessions of Congress and we create new .csv files in a cleanedcsv directory. These new .csv files contain all the data the previous .csv files contained in addition to the new fields outlined in the summary at the top of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n"
     ]
    }
   ],
   "source": [
    "for congress_no in range(1,114): #we loop through all sessions\n",
    "    print congress_no\n",
    "    for body in ['house', 'senate']:\n",
    "        tmp = [] #holds a list of objects for each vote and the objects hold our bill data\n",
    "        path = 'csv/' + str(congress_no) + body + '.csv'   #this is where we stored our first iteration of .csvs\n",
    "        path2 = 'cleanedcsv/' + str(congress_no) + body + '.csv' #this is where we will store our second iteration of .csvs\n",
    "        df = pd.read_csv(path)\n",
    "        subjects_dict = {'committee': [], 'billTitle': [], 'sponsor': [], 'officialTitle': []} #initialize dict for each body\n",
    "        for i in range(0, len(df.title)): #loop through all of the titles and get all of the data from the .json files the titles lead to\n",
    "            get_subjects(df.isAmendment[i], df.title[i])\n",
    "            \n",
    "        count_subjects_dict = {}\n",
    "\n",
    "        for i in range(0, len(tmp)): #loop through all of the votes\n",
    "            if type(tmp[i]) == dict: #this means we found a bill .json and have some of its data\n",
    "                subjects_dict['committee'].append(str(tmp[i]['committee'])) #append the data if it exists or if its a nan\n",
    "                subjects_dict['billTitle'].append(str(tmp[i]['billTitle']))\n",
    "                subjects_dict['officialTitle'].append(tmp[i]['officialTitle'].encode('utf-8'))\n",
    "                subjects_dict['sponsor'].append(str(tmp[i]['sponsor']))\n",
    "                if type(tmp[i]['subjects']) == list:\n",
    "                    #we loop through all of the subjects and create a master dictionary for each body in each session of all subjects addressed\n",
    "                    for j in range(0, len(tmp[i]['subjects'])):\n",
    "                        if tmp[i]['subjects'][j] in count_subjects_dict:\n",
    "                            count_subjects_dict[tmp[i]['subjects'][j]] += 1\n",
    "                        else:\n",
    "                            count_subjects_dict[tmp[i]['subjects'][j]] = 1\n",
    "            else: #we weren't able to find bill .json so we only have nans\n",
    "                subjects_dict['committee'].append(np.nan)\n",
    "                subjects_dict['billTitle'].append(np.nan)\n",
    "                subjects_dict['officialTitle'].append(np.nan)\n",
    "                subjects_dict['sponsor'].append(np.nan)\n",
    "\n",
    "        for key in count_subjects_dict: #loop through all the subjects now and set up the array of 1s and 0s\n",
    "            subjects_dict[key] = find_subject_in_bills(key)\n",
    "        \n",
    "        subjects_df = pd.DataFrame(data=subjects_dict) #basically appends these new fields to our existing .csv file in new path\n",
    "\n",
    "        final = pd.concat([df, subjects_df], axis=1)\n",
    "        final.to_csv(path2, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
